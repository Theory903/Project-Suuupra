# Service PRD: LLM Tutor Service (GPTâ€‘OSS + Hugging Face + LangChain + Voice)

## 1. ðŸŽ¯ The Challenge: Problem Statement & Mission

### Problem Statement
> Traditional online learning lacks the personalized guidance and immediate feedback of a human tutor. We must build an AI tutor that understands student needs, adapts learning paths, and offers realâ€‘time help while staying safe, accurate, ageâ€‘appropriate, and grounded in citations.

### Mission
> Deliver a safe, multimodal tutor on Suuupra using openâ€‘weight **GPTâ€‘OSS** models (served via Hugging Face + vLLM), **LangChain** for RAG, and a robust **voice** stack (Whisper ASR + OpenVoice/Coqui XTTSâ€‘v2 TTS) to produce accessible, grounded learning experiences.

---

## 2. ðŸ§  Core Requirements & Edge Cases

### 2.1 Functional Requirements (FRs)

| FR-ID | Feature | Description |
|---|---|---|
| FR-1 | **Conversational AI (GPTâ€‘OSS)** | Multiâ€‘turn tutor with citations, tool use, and streaming. Start with 20B for latency/cost; scale to 120B when needed. Use Harmony chat format. |
| FR-2 | **RAG & Knowledge Base (LangChain)** | Hybrid retrieval (vector + BM25) with reranking; Parentâ€‘Document and Selfâ€‘Query retrievers for long docs and filtered queries. |
| FR-3 | **Personalized Learning** | Session memory, mastery tracking, spaced practice, difficulty adaptation. |
| FR-4 | **Safety & Moderation** | Input/output classification, deterministic refusal flows, audit logging. |
| FR-5 | **Adaptive Assessment** | Diagnostics, hints, and nextâ€‘bestâ€‘action recommendations; mastery map per topic. |
| FR-6 | **Voice I/O** | **ASR:** Whisper largeâ€‘v3. **TTS:** OpenVoice or Coqui XTTSâ€‘v2 for natural multilingual output; cloning only with explicit consent. |

### 2.2 Nonâ€‘Functional Requirements (NFRs)

| NFR-ID | Requirement | Target | Notes |
|---|---|---|---|
| NFR-1 | **Latency** | p95 < 2 s | vLLM PagedAttention + continuous batching; token streaming for UX. |
| NFR-2 | **Grounded Accuracy** | > 90% | Evaluate via RAG triad: context relevance, groundedness, answer relevance. |
| NFR-3 | **Safety** | < 0.1% harmful passâ€‘through | Layered filters + redâ€‘teaming prior to release. |
| NFR-4 | **Embeddings Throughput** | Burst to 10k QPS | Serve embeddings via Hugging Face **Text Embeddings Inference (TEI)**. |

### 2.3 Edge Cases & Failure Scenarios
- **Hallucinations:** Retrievalâ€‘first prompting; rerank and corrective flow when low retrieval confidence is detected.
- **Harmful/unsafe content:** Classify inputs/outputs; deterministic refusals; capture traces for audit.
- **Student disengagement:** Detect frustration markers (rapid turns, dropâ€‘offs) and switch to stepâ€‘byâ€‘step coaching or simpler problems.

---

## 3. ðŸ—ºï¸ Architecture & Design

### 3.1 System Architecture Diagram
```mermaid
flowchart LR
  C[Client (Web/Mobile/Voice)] --> |Text/Audio| GW[API Gateway]
  GW --> Auth[Auth & Policy]
  GW --> Orch[Conversation Orchestrator (LangChain graph)]
  Orch --> Retr{RAG Router}
  Retr --> V[(Vector Store)]
  Retr --> B[BM25 Index]
  V --> RR[Reranker]
  B --> RR
  RR --> Ctx[Context Pack]
  Orch --> LLM[GPTâ€‘OSS via vLLM]
  Ctx --> LLM
  LLM --> Safe[Safety & Policy Filters]
  Safe --> VO{Voice Out?}
  VO --> |Yes| TTS[OpenVoice / XTTSâ€‘v2]
  VO --> |No| Out[Text Response]
  TTS --> Out
  GW --> Obs[Observability (Tracing, Metrics, Grafana)]
```

### 3.2 Tech Stack

| Component | Technology | Notes |
|---|---|---|
| **LLM Serving** | GPTâ€‘OSSâ€‘20B/120B on Hugging Face; **vLLM** | 20B fits ~16 GB; 120B targets ~80 GB. Use Harmony prompt format; consider MXFP4/quant for fit and throughput. |
| **Backend** | Python 3.11, FastAPI | Async/streaming APIs; policy hooks. |
| **RAG** | **LangChain** | Parentâ€‘Document, Selfâ€‘Query, contextual compression, crossâ€‘encoder reranker. |
| **Embeddings** | HF models via **TEI** | Production embedding server; integrates with Milvus/Chroma/Pinecone. |
| **Vector DB** | Milvus / Pinecone / Chroma | Hybrid retrieval, metadata filters. |
| **Reranking** | Crossâ€‘encoder (open CE) | Improves precision on topâ€‘k candidates. |
| **ASR** | Whisper largeâ€‘v3 | Robust multilingual speech recognition. |
| **TTS** | OpenVoice / Coqui XTTSâ€‘v2 | Instant cloning, multilingual synthesis (consent required). |
| **Observability** | Traces + Prometheus/Grafana | Latency, retrieval hit@k, WER, safety events. |

### 3.3 Key Components
- **RAG Pipeline:** Hybrid search (vector + BM25), rerank with crossâ€‘encoder; Parentâ€‘Document fetch to broaden context; Selfâ€‘Query for structured filters.
- **Serving:** vLLM PagedAttention and continuous batching for SLA compliance.
- **Voice:** Whisper ASR; TTS via OpenVoice or XTTSâ€‘v2 with clear consent UI and logging.

---

## 4. ðŸš€ Implementation Phases

> Duration: **10 weeks** total. Parallelize where feasible.

### Phase 0 â€” Foundations (Week 1)
**Objective:** Stand up core serving and storage.  
**Tasks:**
- Deploy GPTâ€‘OSSâ€‘20B via vLLM with streaming; validate Harmony prompts.
- Spin up embeddings via HF **TEI**.
- Provision vector database (Milvus/Pinecone/Chroma).  
**Exit Criteria:**
- Response tokenâ€‘start p95 â‰¤ 600 ms warm.
- Embeddings QPS â‰¥ 2k single instance.

### Phase 1 â€” RAG v1 (Weeks 2â€“3)
**Objective:** Working retrieval and citations.  
**Tasks:**
- Content ingestion + chunking.
- Embedding pipeline + hybrid retrieval (vector + BM25).
- Integrate reranker and contextual compression.  
**Exit Criteria:**
- Tutor answers include â‰¥ 2 citations.
- Groundedness â‰¥ 0.85 on pilot eval set; p95 â‰¤ 2 s at 10 RPS.

### Phase 2 â€” Conversation & Safety (Weeks 4â€“5)
**Objective:** Durable sessions + policy guardrails.  
**Tasks:**
- Redisâ€‘backed session memory and learner profile store.
- Input/output classification; refusal templates; audit logging.  
**Exit Criteria:**
- < 0.1% unsafe passâ€‘through on staged redâ€‘team corpus.
- Full traceability of blocked/allowed decisions.

### Phase 3 â€” Voice I/O (Week 6)
**Objective:** Voice input and readâ€‘aloud output.  
**Tasks:**
- Whisper ASR API; language autoâ€‘detect, punctuation.
- TTS via OpenVoice or XTTSâ€‘v2; consent flow for cloning; watermarks/logs.  
**Exit Criteria:**
- ASR WER meets domain target.
- TTS latency < 700 ms for short utterances.

### Phase 4 â€” Adaptive Assessment & Personalization (Weeks 7â€“8)
**Objective:** Diagnostics, mastery map, and nextâ€‘bestâ€‘action.  
**Tasks:**
- Item bank; difficulty adaptation; spacedâ€‘practice scheduler.  
**Exit Criteria:**
- Mastery deltas observable over 1â€‘week cohorts.
- Hint efficiency improves weekâ€‘overâ€‘week.

### Phase 5 â€” Evals, Observability, Launch Readiness (Weeks 9â€“10)
**Objective:** Hardening and compliance.  
**Tasks:**
- Traces, metrics, dashboards, SLOs.
- Load tests; privacy & consent UX (DSR export/delete).  
**Exit Criteria:**
- p95 latency â‰¤ 2 s at target RPS.
- DSR/consent flows verified; launch checklist passed.

---

## 5. ðŸ§ª Testing & Quality Strategy

| Layer | Tools | Scope |
|---|---|---|
| Unit | `pytest` | Prompt utils, chunkers, safety adapters, reranker wrapper |
| Integration | Testcontainers | Endâ€‘toâ€‘end RAG: embed â†’ retrieve â†’ rerank â†’ answer |
| E2E | Cypress | Tutor journeys, quizzes, voice readâ€‘aloud |
| LLM Evals | Custom + LangChain evals | RAG triad, citation correctness, refusal correctness |
| Red Team | Curated prompts | Jailbreaks, data leakage, unsafe topics |

---

## 6. ðŸ”­ Monitoring & Alerting

**KPIs**
- **Technical:** p95 latency, tokens/s, retrieval hit@k, reranker NDCG/MRR, ASR WER, safety events.
- **Learning:** Mastery gains, hint efficiency, session retention.

**Alerts**
- `HighResponseLatency` if p99 > 2 s for 5 min.
- `LowGroundedness` below threshold on rolling window.
- `SafetyFilterFailure` on any unblocked critical event.

---

## 7. ðŸ“š Knowledge Base & References

- GPTâ€‘OSS models and Harmony prompt schema.
- vLLM serving features (PagedAttention, batching).
- LangChain retrievers: Parentâ€‘Document, Selfâ€‘Query, compression + reranker.
- Hugging Face **TEI** for highâ€‘throughput embeddings.
- Whisper largeâ€‘v3 (ASR), OpenVoice / Coqui XTTSâ€‘v2 (TTS).

---

## 8. âœ… Acceptance Criteria

- Tutor responses return p95 < 2 s with â‰¥ 2 citations on RAG queries.
- Groundedness â‰¥ 0.90 on curated eval set; citation correctness â‰¥ 0.95.
- < 0.1% unsafe I/O over 10k staged turns.
- Voice: ASR WER meets domain target; TTS latency < 700 ms for short utterances.
- Privacy: DSR export/delete and consent flows verified.

---

## 9. ðŸ”§ Implementation Notes

- Start on **GPTâ€‘OSSâ€‘20B** (fits ~16 GB); scale to **120B** on 80 GB (H100/MI300X) as usage grows.
- Lock prompts to **Harmony** format for consistent outputs.
- Use **TEI** for embeddings throughput; compatible with Milvus/Chroma/Pinecone.
- Rerank after hybrid retrieval to boost precision (open crossâ€‘encoder works well).

---

## 10. ðŸ“Ž Appendix: Model IDs (Hugging Face)

- LLM: `openai/gpt-oss-20b`, `openai/gpt-oss-120b`
- ASR: `openai/whisper-large-v3`
- TTS: `myshell-ai/OpenVoice` (or `myshell-ai/OpenVoiceV2`), `coqui/XTTS-v2`
- Embedding server: Hugging Face Text Embeddings Inference (TEI)
